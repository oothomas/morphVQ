{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, std, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "        \n",
    "    cm = cm.astype('float')\n",
    "    std = std.astype('float')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6), dpi=300)\n",
    "\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    ax.set_title(title, fontsize = 16) \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    fmt_std = '.3f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt), fontsize=15,\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            ax.text(j, i+0.2, '('+format(std[i, j], fmt_std)+')', fontsize=12,\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat(\"lssd_pca_118.mat\")\n",
    "\n",
    "names = [name[0][0] for name in data['names']]\n",
    "names_df = pd.DataFrame([name.split('_') for name in names], columns=['Genus', 'Catalog_No', '1','2']).iloc[:,:2]\n",
    "names_df['ID'] = names\n",
    "\n",
    "hominoids = pd.read_csv('hominoid_procrustes_coordinates.csv')\n",
    "hominoids = hominoids[hominoids['ID'].isin(names)]\n",
    "new_names = hominoids[hominoids['ID'].isin(names)]['ID']\n",
    "hominoids = hominoids.set_index('ID')\n",
    "\n",
    "hominoid_landmarks = pd.read_csv('Cuboid_21L_coords.csv')\n",
    "hominoid_landmarks = hominoid_landmarks[hominoid_landmarks['ID'].isin(new_names)]\n",
    "hominoid_landmarks = hominoid_landmarks.set_index('ID')\n",
    "\n",
    "auto3dgm = pd.read_csv('auto3dgm_procrustes_coordinates_12K_256.csv') #auto3dgm_procrustes_coordinates_12K_512\n",
    "auto3dgm = auto3dgm[auto3dgm['ID'].isin(new_names)]\n",
    "auto3dgm = auto3dgm.set_index('ID')\n",
    "\n",
    "auto3dgm2 = pd.read_csv('auto3dgm_procrustes_coordinates_12K_256.csv')\n",
    "auto3dgm2 = auto3dgm2[auto3dgm2['ID'].isin(new_names)]\n",
    "auto3dgm2 = auto3dgm2.set_index('ID')\n",
    "\n",
    "area_lssds = pd.concat([names_df, pd.DataFrame(data['area_based'][:,:4900], columns=['L' + str(j) for j in list(range(1,4901))])], axis=1)\n",
    "area_lssds = area_lssds[area_lssds['ID'].isin(new_names)]\n",
    "area_lssds = area_lssds.set_index('ID')\n",
    "\n",
    "conf_lssds = pd.concat([names_df, pd.DataFrame(data['conf_based'][:,:4900], columns=['L' + str(j) for j in list(range(1,4901))])], axis=1)\n",
    "conf_lssds = conf_lssds[conf_lssds['ID'].isin(new_names)]\n",
    "conf_lssds = conf_lssds.set_index('ID')\n",
    "\n",
    "auto3dgm_y = auto3dgm['Genus']\n",
    "auto3dgm2_y = auto3dgm['Genus']\n",
    "hominoid_y = hominoids['Genus']\n",
    "hominoid_landmarks_y = hominoid_landmarks['Genus']\n",
    "area_lssds_y = area_lssds['Genus']\n",
    "conf_lssds_y = conf_lssds['Genus']\n",
    "\n",
    "conf_area_lssds = pd.concat([conf_lssds,area_lssds], axis=1)\n",
    "conf_area_lssds_y = area_lssds['Genus']\n",
    "\n",
    "del conf_area_lssds['Genus']\n",
    "del conf_area_lssds['Catalog_No']\n",
    "del area_lssds['Genus']\n",
    "del area_lssds['Catalog_No']\n",
    "del conf_lssds['Genus']\n",
    "del conf_lssds['Catalog_No']\n",
    "del auto3dgm['Genus']\n",
    "del auto3dgm2['Genus']\n",
    "del hominoids['Genus']\n",
    "del hominoid_landmarks['Genus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_lssds.to_csv('CUBOID_118_Conformal_LSSDS.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_lssds.to_csv('CUBOID_118_Area-Based_LSSDS.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_area = StandardScaler()\n",
    "scaler_conf = StandardScaler()\n",
    "scaler_auto = StandardScaler()\n",
    "scaler_auto2 = StandardScaler()\n",
    "scaler_coords = StandardScaler()\n",
    "scaler_coords2 = StandardScaler()\n",
    "\n",
    "scalar_conf_area = StandardScaler()\n",
    "\n",
    "skfoldcv = StratifiedKFold(n_splits=11)\n",
    "\n",
    "\n",
    "X_conf_area_scaled = scalar_conf_area.fit_transform(np.array(conf_area_lssds))\n",
    "\n",
    "\n",
    "X_area_scaled = scaler_area.fit_transform(np.array(area_lssds))\n",
    "X_conf_scaled = scaler_conf.fit_transform(np.array(conf_lssds))\n",
    "X_conf_area_scaled = scalar_conf_area.fit_transform(np.array(conf_area_lssds))\n",
    "X_auto_scaled = scaler_area.fit_transform(np.array(auto3dgm))\n",
    "X_auto2_scaled = scaler_area.fit_transform(np.array(auto3dgm2))\n",
    "X_coords_scaled = scaler_coords.fit_transform(np.array(hominoids))\n",
    "X_coords2_scaled = scaler_coords2.fit_transform(np.array(hominoid_landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coords = PCA()\n",
    "pca_coords.fit(X_coords_scaled)\n",
    "\n",
    "X_coords = pca_coords.transform(X_coords_scaled)\n",
    "X_coords_pcs = pd.DataFrame(X_coords[:, :27],\n",
    "                          columns=['PC' + str(j) for j in list(range(1,27+1))],\n",
    "                         index=hominoids.index)\n",
    "X_coords_pcs['Genus'] = hominoid_y\n",
    "X_coords_pcs.Genus = pd.Categorical(X_coords_pcs.Genus)\n",
    "X_coords_pcs['Group'] = X_coords_pcs.Genus.cat.codes\n",
    "y_coords_labels = list(X_coords_pcs['Genus'])\n",
    "y_coords = np.array(X_coords_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_scores = []\n",
    "coords_cnf_matrices = []\n",
    "coords_pred = []\n",
    "coords_y = []\n",
    "\n",
    "for i in range(1000):\n",
    "    new_X_coords, new_y_coords = resample(X_coords[:, :27],y_coords,\n",
    "                                          n_samples=102, replace=True,\n",
    "                                          stratify=y_coords_labels)\n",
    "    coords_y.append(new_y_coords)\n",
    "    model_coords = LogisticRegression(max_iter=1000)\n",
    "    scores = cross_val_score(model_coords, new_X_coords, new_y_coords,\n",
    "                             scoring='accuracy', cv=skfoldcv, n_jobs=-1)\n",
    "    coords_scores.append(scores)\n",
    "    y_pred = cross_val_predict(model_coords, new_X_coords, new_y_coords, cv=skfoldcv, n_jobs=-1)\n",
    "    coords_pred.append(y_pred)\n",
    "    cnf = confusion_matrix(new_y_coords, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "    cnf = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "    coords_cnf_matrices.append(cnf)\n",
    "print(classification_report(np.concatenate(coords_y,axis=0),\n",
    "                            np.concatenate(coords_pred,axis=0),\n",
    "                            target_names=['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cnf = np.array(coords_cnf_matrices).mean(axis=0)\n",
    "new_cnf_std = np.array(coords_cnf_matrices).std(axis=0)\n",
    "plot_confusion_matrix(new_cnf, new_cnf_std, ['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo'],\n",
    "                      title='(A) Semilandmark Patches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coords2 = PCA()\n",
    "pca_coords2.fit(X_coords2_scaled)\n",
    "X_coords2 = pca_coords2.transform(X_coords2_scaled)\n",
    "# sum(pca_coords2.explained_variance_[:27])/sum(pca_coords2.explained_variance_)\n",
    "\n",
    "X_coords2_pcs = pd.DataFrame(X_coords2[:, :27],\n",
    "                          columns=['PC' + str(j) for j in list(range(1,27+1))],\n",
    "                         index=hominoid_landmarks.index)\n",
    "X_coords2_pcs['Genus'] = hominoid_landmarks_y\n",
    "X_coords2_pcs.Genus = pd.Categorical(X_coords2_pcs.Genus)\n",
    "X_coords2_pcs['Group'] = X_coords2_pcs.Genus.cat.codes\n",
    "y_coords2_labels = list(X_coords2_pcs['Genus'])\n",
    "y_coords2 = np.array(X_coords2_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords2_scores = []\n",
    "coords2_cnf_matrices = []\n",
    "coords2_pred = []\n",
    "coords2_y = []\n",
    "\n",
    "for i in range(1000):\n",
    "    new_X_coords2, new_y_coords2 = resample(X_coords2[:, :27],y_coords2,\n",
    "                                          n_samples=102, replace=True,\n",
    "                                          stratify=y_coords2_labels)\n",
    "    coords2_y.append(new_y_coords2)\n",
    "    model_coords2 = LogisticRegression(max_iter=1000)\n",
    "    scores = cross_val_score(model_coords2, new_X_coords2, new_y_coords2,\n",
    "                             scoring='accuracy', cv=skfoldcv, n_jobs=-1)\n",
    "    coords2_scores.append(scores)\n",
    "    y_pred = cross_val_predict(model_coords2, new_X_coords2, new_y_coords2, cv=skfoldcv, n_jobs=-1)\n",
    "    coords2_pred.append(y_pred)\n",
    "    cnf = confusion_matrix(new_y_coords2, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "    cnf = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "    coords2_cnf_matrices.append(cnf)\n",
    "print(classification_report(np.concatenate(coords2_y,axis=0),\n",
    "                            np.concatenate(coords2_pred,axis=0),\n",
    "                            target_names=['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cnf = np.array(coords2_cnf_matrices).mean(axis=0)\n",
    "new_cnf_std = np.array(coords2_cnf_matrices).std(axis=0)\n",
    "plot_confusion_matrix(new_cnf, new_cnf_std, ['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo'],\n",
    "                      title='(A) 21 Homologous Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_auto2 = PCA()\n",
    "pca_auto2.fit(X_auto2_scaled)\n",
    "X_auto2 = pca_auto2.transform(X_auto2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca_auto2.explained_variance_[:54])/sum(pca_auto2.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_auto2_pcs = pd.DataFrame(X_auto2[:, :54], #52 for 256, 64 for 512\n",
    "                          columns=['PC' + str(j) for j in list(range(1,54+1))],\n",
    "                         index=auto3dgm2.index)\n",
    "X_auto2_pcs['Genus'] = auto3dgm2_y\n",
    "X_auto2_pcs.Genus = pd.Categorical(X_auto2_pcs.Genus)\n",
    "X_auto2_pcs['Group'] = X_auto2_pcs.Genus.cat.codes\n",
    "y_auto2_labels = list(X_auto2_pcs['Genus'])\n",
    "y_auto2 = np.array(X_auto2_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_auto = PCA()\n",
    "pca_auto.fit(X_auto_scaled)\n",
    "X_auto = pca_auto.transform(X_auto_scaled)\n",
    "X_auto_pcs = pd.DataFrame(X_auto[:, :54], #52 for 256, 64 for 512\n",
    "                          columns=['PC' + str(j) for j in list(range(1,54+1))],\n",
    "                         index=auto3dgm.index)\n",
    "X_auto_pcs['Genus'] = auto3dgm_y\n",
    "X_auto_pcs.Genus = pd.Categorical(X_auto_pcs.Genus)\n",
    "X_auto_pcs['Group'] = X_auto_pcs.Genus.cat.codes\n",
    "y_auto_labels = list(X_auto_pcs['Genus'])\n",
    "y_auto = np.array(X_auto_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_scores = []\n",
    "auto_cnf_matrices = []\n",
    "auto_pred = []\n",
    "auto_y = []\n",
    "for i in range(1000):\n",
    "    new_X_auto, new_y_auto = resample(X_auto[:, :54], y_auto, n_samples=102, replace=True, stratify=y_auto_labels)    \n",
    "    auto_y.append(new_y_auto)\n",
    "    \n",
    "    model_auto = LogisticRegression(max_iter=1000)\n",
    "    scores = cross_val_score(model_auto, new_X_auto, new_y_auto,\n",
    "                             scoring='accuracy', cv=skfoldcv, n_jobs=-1)\n",
    "    auto_scores.append(scores)\n",
    "    y_pred = cross_val_predict(model_auto, new_X_auto, new_y_auto, cv=skfoldcv, n_jobs=-1)\n",
    "    auto_pred.append(y_pred)\n",
    "    \n",
    "    cnf = confusion_matrix(new_y_auto, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "    cnf = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "    auto_cnf_matrices.append(cnf)\n",
    "print(classification_report(np.concatenate(auto_y,axis=0),\n",
    "                            np.concatenate(auto_pred,axis=0),\n",
    "                            target_names=['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_auto_cnf = np.array(auto_cnf_matrices).mean(axis=0)\n",
    "new_auto_cnf_std = np.array(auto_cnf_matrices).std(axis=0)\n",
    "plot_confusion_matrix(new_auto_cnf, new_auto_cnf_std,\n",
    "                      ['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo'],\n",
    "                      title='(B) Auto3DGM Pseudo-Landmarks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_conf_area = PCA()\n",
    "pca_conf_area.fit(X_conf_area_scaled)\n",
    "X_conf_area = pca_conf_area.transform(X_conf_area_scaled)\n",
    "# sum(pca_conf_area.explained_variance_[:64])/sum(pca_conf_area.explained_variance_)\n",
    "X_conf_area_pcs = pd.DataFrame(X_conf_area[:,:64],\n",
    "                          columns=['PC' + str(j) for j in list(range(1,64+1))],\n",
    "                         index=conf_area_lssds.index)\n",
    "X_conf_area_pcs['Genus'] = conf_area_lssds_y\n",
    "X_conf_area_pcs.Genus = pd.Categorical(X_conf_area_pcs.Genus)\n",
    "X_conf_area_pcs['Group'] = X_conf_area_pcs.Genus.cat.codes\n",
    "y_conf_area_labels = list(X_conf_area_pcs['Genus'])\n",
    "y_conf_area = np.array(X_conf_area_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_area_scores = []\n",
    "conf_area_cnf_matrices = []\n",
    "conf_area_pred = []\n",
    "conf_area_y = []\n",
    "\n",
    "for i in range(1000):\n",
    "    new_X_conf_area, new_y_conf_area = resample(X_conf_area[:,:64], y_conf_area, n_samples=102, replace=True, stratify=y_conf_area_labels)    \n",
    "    conf_area_y.append(new_y_conf_area)\n",
    "    model_conf_area = LogisticRegression(max_iter=1000)\n",
    "    scores = cross_val_score(model_conf_area, new_X_conf_area, new_y_conf_area,\n",
    "                             scoring='accuracy', cv=skfoldcv, n_jobs=-1)\n",
    "    conf_area_scores.append(scores)\n",
    "    y_pred = cross_val_predict(model_conf_area, new_X_conf_area, new_y_conf_area, cv=skfoldcv, n_jobs=-1)\n",
    "    conf_area_pred.append(y_pred)\n",
    "    cnf = confusion_matrix(new_y_conf_area, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "    cnf = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "    conf_area_cnf_matrices.append(cnf)\n",
    "    \n",
    "print(classification_report(np.concatenate(conf_area_y,axis=0),\n",
    "                            np.concatenate(conf_area_pred,axis=0),\n",
    "                            target_names=['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conf_area_cnf = np.array(conf_area_cnf_matrices).mean(axis=0)\n",
    "new_conf_area_cnf_std = np.array(conf_area_cnf_matrices).std(axis=0)\n",
    "plot_confusion_matrix(new_conf_area_cnf, new_conf_area_cnf_std,\n",
    "                      ['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo'],\n",
    "                      title='Conformal and Area Latent Shape Space Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_area = PCA()\n",
    "pca_area.fit(X_area_scaled)\n",
    "X_area = pca_area.transform(X_area_scaled)\n",
    "X_area_pcs = pd.DataFrame(X_area[:,:60],\n",
    "                          columns=['PC' + str(j) for j in list(range(1,60+1))],\n",
    "                         index=area_lssds.index)\n",
    "X_area_pcs['Genus'] = area_lssds_y\n",
    "X_area_pcs.Genus = pd.Categorical(X_area_pcs.Genus)\n",
    "X_area_pcs['Group'] = X_area_pcs.Genus.cat.codes\n",
    "y_area_labels = list(X_area_pcs['Genus'])\n",
    "y_area = np.array(X_area_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_scores = []\n",
    "area_cnf_matrices = []\n",
    "area_pred = []\n",
    "area_y = []\n",
    "\n",
    "for i in range(1000):\n",
    "    new_X_area, new_y_area = resample(X_area[:,:60], y_area, n_samples=102, replace=True, stratify=y_area_labels)    \n",
    "    area_y.append(new_y_area)\n",
    "    model_area = LogisticRegression(max_iter=1000)\n",
    "    scores = cross_val_score(model_area, new_X_area, new_y_area,\n",
    "                             scoring='accuracy', cv=skfoldcv, n_jobs=-1)\n",
    "    area_scores.append(scores)\n",
    "    y_pred = cross_val_predict(model_area, new_X_area, new_y_area, cv=skfoldcv, n_jobs=-1)\n",
    "    area_pred.append(y_pred)\n",
    "    cnf = confusion_matrix(new_y_area, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "    cnf = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "    area_cnf_matrices.append(cnf)\n",
    "    \n",
    "print(classification_report(np.concatenate(area_y,axis=0),\n",
    "                            np.concatenate(area_pred,axis=0),\n",
    "                            target_names=['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_area_cnf = np.array(area_cnf_matrices).mean(axis=0)\n",
    "new_area_cnf_std = np.array(area_cnf_matrices).std(axis=0)\n",
    "plot_confusion_matrix(new_area_cnf, new_area_cnf_std,\n",
    "                      ['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo'],\n",
    "                      title='(D) Area Latent Shape Space Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_conf = PCA()\n",
    "pca_conf.fit(X_conf_scaled)\n",
    "X_conf = pca_conf.transform(X_conf_scaled)\n",
    "X_conf_pcs = pd.DataFrame(X_conf[:, :59],\n",
    "                          columns=['PC' + str(j) for j in list(range(1,59+1))],\n",
    "                         index=conf_lssds.index)\n",
    "X_conf_pcs['Genus'] = conf_lssds_y\n",
    "X_conf_pcs.Genus = pd.Categorical(X_conf_pcs.Genus)\n",
    "X_conf_pcs['Group'] = X_conf_pcs.Genus.cat.codes\n",
    "y_conf_labels = list(X_conf_pcs['Genus'])\n",
    "y_conf = np.array(X_conf_pcs['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_scores = []\n",
    "conf_cnf_matrices = []\n",
    "conf_pred = []\n",
    "conf_y = []\n",
    "for i in range(1000):\n",
    "    new_X_conf, new_y_conf = resample(X_conf[:, :59],y_conf,\n",
    "                                          n_samples=102, replace=True,\n",
    "                                          stratify=y_conf_labels)\n",
    "    conf_y.append(new_y_conf)\n",
    "    model_conf = LogisticRegression(max_iter=1000)\n",
    "    scores = cross_val_score(model_conf, new_X_conf, new_y_conf,\n",
    "                             scoring='accuracy', cv=skfoldcv, n_jobs=-1)\n",
    "    conf_scores.append(scores)\n",
    "    y_pred = cross_val_predict(model_conf, new_X_conf, new_y_conf, cv=skfoldcv, n_jobs=-1,)\n",
    "    conf_pred.append(y_pred)\n",
    "    \n",
    "    cnf = confusion_matrix(new_y_conf, y_pred, labels=[0, 1, 2, 3, 4])\n",
    "    cnf = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "    conf_cnf_matrices.append(cnf)\n",
    "print(classification_report(np.concatenate(conf_y,axis=0),\n",
    "                            np.concatenate(conf_pred,axis=0),\n",
    "                            target_names=['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conf_cnf = np.array(conf_cnf_matrices).mean(axis=0)\n",
    "new_conf_cnf_std = np.array(conf_cnf_matrices).std(axis=0)\n",
    "plot_confusion_matrix(new_conf_cnf, new_conf_cnf_std,\n",
    "                      ['Gorilla', 'Homo', 'Hylobates', 'Pan', 'Pongo'],\n",
    "                      title='(C) Conformal Latent Shape Space Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(coords_scores), np.std(coords_scores)),\\\n",
    "(np.mean(coords2_scores), np.std(coords2_scores)),\\\n",
    "(np.mean(auto_scores), np.std(auto_scores)),\\\n",
    "(np.mean(area_scores), np.std(area_scores)),\\\n",
    "(np.mean(conf_scores), np.std(conf_scores)),\\\n",
    "(np.mean(conf_area_scores), np.std(conf_area_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(auto_scores), np.std(auto_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shape_matching)",
   "language": "python",
   "name": "shape_matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
